::: System Designs Notes :::

Link: https://www.geeksforgeeks.org/system-design-tutorial/

** System Design ?

- Process of designing the architecture and components of a system to meet business requirements.
- Process includes designing of architecture, components, interfaces, identify tech/tools to use.
- Architecture [Major Components connected via interfaces  [APIs] between them]
- Attention to security, privacy and scalability.
- System Design is the blueprint for the developmentand implementation of a comp system to meet user's needs.


* 3 importants Factors affecting designing of System:

1) Reliability.
	- It must implements all mandatory features as per end-user requirement.
	- Fault Tolerant: System must continue to work inspite of faults.
		- Fault: Errors in a particular component, but this doesnot always mean the System stop providing service.
		- Failures: System State when it's no longer able to provide certain service to end-user.

2) Availability.
	- Also called uptime, ensures an agreed level of Operational Performance of the system.
	- Example, Instagram can handle a delay of 5s-10s to display images, wont effect users much, but in Banking application, a dealy means huge loss.
	- Principles:
	  - System should avoid using a single point of Failure.
	  - If System depends upon a single service and that fails, then the whole system will be unavailable.

3) Scalability.
	- ability of the system to cope with increasing load.
	- example, E-commerce Websites experience a spike of users during flash sales. System should be able to handle this.
	- What are loads ?
	  - Amount users online.
	  - number of database calls made.
	  - number of requests coming to system per day.
	  

** Advantages of System Design: 

 -- Imporved Efficieny, Scalability, Improved User Experience, Better Security, Better Integration.
 
 

** Disadvantage System Design:
 
 -- Complex Systems, Increased Costs, Longer devlopment time, difficult to adapt to changes in req, complex system --> More Possiblities for Errors.
 
 

 
** Functional Vs Non Functional Requirements [ Requirements Analysis ]

* Functional Requirements:
  - Features those are mandatory as per the end-user's Requirements.
  - This are Functionalities/features that must be provides and can be seen in the final Product.
  
  
* Non Functional Requirements:
	- includes Quality Constraints for enhancing the quality of the project.
	- Also Called Non-behavioral requirements.
	eg: Portablity, security, Maintainability, Reliablity, scalability, Performance, Flexibility
	
** Comparing Functional vs Non Functional Requirement:

Functional:
	- defines a system or components, defined based on user's requirement.
	- specify on "What Our System will do ?"
	- It is mandatory, Captures all use case of the project.
	

Non Functional:
	- defines the quality attribute of the project.
	- Specify on "How well the project fullfills the functional Requirements ?"
	- It is non mandatory, Takes care of our Project's Quality.


	
** What are all the components of System Design ?

1) Load Balancer:
   -- distributes incoming requests/workload across a number of different resources/server.
   -- useCase: When system receives a large number of request and need to distribute them among multiple servers to avoid overloading one server.
   -- One of the key Component, Enables the system to efficiently use it's resources without overloading them.
   -- Types: 
      1) Layer 4 load balancers
			- Operates at Network layer of the OSI Model.
			- Distributes req based on source and destination IP address and port number.
	  2) Layer 7 load balancers
			- Operates at Application Level.
			- distributes req based on content of req eg: URL or type of HTTP Method used.
	  3) Global load balancers
			- Used in distributed systems.
			- distributes req among multiple servers located in different geo locations.
	  4) Application load balancers 
			- specialized load balancers
			- Work with a sepecific type of app or protocol eg: either HTTP or HTTPs
	  
	  
	NOTE: 
	 - OSI -> Open System Intercommunication, Conceptual model of how netwrok communication work.
	 - 7 Layers of OSI: 
		- Application: End User Layer [HTTP, FTP]
		- Presentation: Syntax Layer [SSL, SSH]
		- Session: Synch & send to port [APIs, Sockets]
		- Transport: End to End connections [TCP, UDP]
		- Network: Packets [IP]
		- Data Link: Framses [Ethernet, Switch, Bridges]
		- Physical: Physical devices [Hubs, Repeaters, Fibers]

2) Key-value stores:
	-- store data as a set of key-value pairs, like noSQL.
	-- each piece of data is stored under a unique key.
	-- useCase: 
	   It stores data which are accessed frequently, provide fast access.
	-- types:
		1) In-Memory Key-Value Stores: Stores in the memory
		2) Persistent Key-Value Stores: Stores in the physical disk.
	-- Where we use key-value stores ?
	   - For Storing caching, session management and real-time analytics.
	-- How different from using RDMS ?
		- Key-value stores are simpler to use and more scalable, they are not used for storing complex and structured data that required query.
		
	-- In Distributed System How key-value stores are used ?
		- They stores data that need quick access across nodes.
		- They can store meta-data or auxiliary data used by System.
	
3) Blob storage & Databases:
	- Blob storage and Database are different but both are used to store and manage Data.
	- Blob Storage:
		- Known as Object Storage, Designed to stored large amount of unstructured data eg: images, documents, videos or audio files.
		- They are highly scalable and can handle multiple concurrent calls.
		- They are used to stored data that are accessed frequently, like media files or user-generated content.
	
	- Structured Storage:
		- Stores structured data that are organized in a specific way.
		- eg: RDMS, NoSQL, in-memory database.
		- Data has to be queried from these kind of databases.
		
	- In Distributed System ?
		- Both Blob and Database storage can be used together depending upon requirement.
	  
4) Rate limiters:
    -- This components used to limit the rate at which the system/application process request or any actions.
    -- usecase:
       - Protects the application from being overloaded with too many requests.
       - Ensures the system can handle high volume of data without being overwhelmed. --> Ensures consistent and reliable.
    -- Types of Rate Limiters:
       1) Request Rate Limiters - Limit the no. of req application process within a given time period.
       2) Action Rate Limiters - Limit the no. of time a specific action can be performed.
       3) User Rate Limiters - Limit the rate at which a user/userGroup can make request.
       4) Token bucket Rate Limiters - Limit the no. of req. that the app can process at a given time, excess req will be hold in the bucket.

5) Monitoring System:
    -- Used to collect, Analysis and report  various application's metrics and Performance data.
    -- useCase:
       - Tracks Application's performance and system Availability.
    -- Types of Monitoring systems:
        1) Network - monitor performance of network and it's components like router, switches and servers.
        2) System - monitor System's performance like CPU, memory and disk usage.
        3) Application - monitor's specific application services like web servers or databases.
        4) Infrastructure - monitor's underlying infrastructre like virtual machines or containers.

6) Distributes system messaging queue:
    -- Enables Exchange of messages between different nodes in distributed system asynchronously.
    -- useCase:
        - enbales communication between different components, like microservices or distributed applications.
        - Also, It Enables decoupling of big components into smaller one, which can work independently while maintaining communication between them.
    -- Types:
        1) Point to Point Queues - messages delivered to a specific recipients.
        2) Publish-Subscribe Queues - messages are published to a topic and are delivered to all subscribers of that topic.
        3) Hybrid Queues - uses both of the above methods.
    -- Tools that implements distributed messaging Queues: 
        - Apache Kafka, TabbitMQ, Amazon Simple Queue Service (SQS) 

7) Distribute unique id generator:
    -- Generates unique Ids to identify Objects and entities in distributed system.
    -- Way to generate unique Ids:
       1) using centralized service.
       2) Using distributed consensus algo.
       3) using timestamps. 

8) Distributes search
    -- Involves using multiple Nodes or servers to index and search large datasets in distributed system.
    -- useCase:
        - Improves the performance and scalability --> perfroms parallel processing of search queries across nodes.
    -- Implementation:
        1) using distributed Search engine.
            - A search platform that is designed to scale horizontally across nodes.
            - eg: Elasticsearch and Apache Solr.
            - uses distributed index to store the data that being search, allows parallel processing of queries.
        2) using db with search capabilities.
            - MongoDB and Cassandra DB supports built-in search capabilities for indexing and search data.
        3) using cloud based search service.
            - cloud-based search services eg: Amazon elasticsearch or Google cloud search.
            - These services are highly scalable and fault-tollerent.

9) Distributed logging services:
    -- Practice of Collecting, storing and analysing log data from multiple source.
    -- useCase:
       - helpful for tracking the health and performance of the System.
       - use for debugging issues.
    -- Implementations:
        1) centralized logging service.
        2) distributed logging service.
        3) cloud-based logging service. 

10) Distributes task scheduler:
    -- responsible for scheduling and executing tasks in distributed system.
    -- useCase:
        - It is used to automate execution of tasks at regular intervals Or on specific schedule or in response of certain events.
    -- Implementations:
        1) Standalone task scheduler 
            - seperate system to schedule and execture tasks. 
            - Simple to implement, Flexible to type of task that can be scheduled but difficult to manage, needs extra infrastructure.
        2) Built-in task scheduler 
            - In container orchestration platform or cloud-based serverless platform has inbuilt task schedulers. 
            - simple to implement and manage but less flexible.
        3) Cloud-based task scheduler
            - eg: Amamzon Simple Notification Service (SNS) or Google Cloud scheduler.
            - Highly scalable, fault-tolerant, No need to manage any on-prem infrastructure.


** What is SDLC (System Design Life cycle) ?

- Involves the Steps in desiging and developing a system, be it a software application, hardware solution or integrated system involving both.
- Phases/Stages of SDLC:
    1) Planning - undertanding project goals, scope and resources.
    2) Feasibility - Ponder on the practicality of the purposed solution.
    3) System Design - Design the blueprint of the System Architecture and it's various components.
    4) Implementation - designs ----> Operational System. [Developers write code to convert the design into a Working Service/Application ]
    5) Test - Verify the System meets the expected requirements.
    6) Deployment - If all goes well, Introduce the System to it's Environment.
    7) Maintenance and Support - Ensure services working fine, resolve bugs if any.

- Challenges for SDLC ?
    1) Unclear Requirements.
    2) Changing Requirements.
    3) Keeping uptodate with the Tech.
    4) Integration Challenges
    5) Scaling and performance Issues.

- Models used for SDLC ?
    1) Waterfall Model
        - Linear, sequential model, Each phase must complete before moving to next.
        - Not applicable for constantly changing requirements.
    2) Iterative Model
        - Involves repeating cycles, Each Iteration refines and improve the system based on feedback.
        - adaptable to changing requirements.
    3) Prototyping Model
        - involves in building a prototype of system --> gather feedback --> Develop the final system.
    4) Spiral Model
        - Iterative + Prototyping Model.
    5) Agile Model
        - More Flexible and collaborative Model.
        - With Frequent iterations and continuous feedback, product is developed in parts of sprint.
        - Well suited for where requirements evolves with time.

** What is Structured Analysis and Structured Design (SA/SD) ?

- based on principal of structured programming, breaking down software systems into smaller managable components.
- 2 Phases:
1) System Analysis (SA)
    - Problem is Analysised and requirements are gathered.
    - Involves: 
        Data Flow Diagram [ Model describes the flow of data in the system ], 
        Data Dictionary [ defines Data stores and Data elements that flow between processes ], 
        State Transition Diagram [ time to execute a fucntion and data access triggered by events ], 
        ER Diagram [Defines a Relationship between the data stores --> Use for Schema design ],

2) System Design (SD)
    - Involves Designing the System to meet the requirements.
    - Involves: 
        Structured charts [Specify how DFS processes are grouped into tasks and allocated to CPU] 
        Pseudo Code [Actual Implementation of the System, Programming language/technology independent]

- Disadvantages: time-consuming, Inflexibility, Limited Iteration.[Only 1 allowed, not for System with Iterative Requirements]


** System Design Strategy ?

- Refers to the approch that is taken to design a system.
- A Good System design organise the program module in such a way that it is easy to develop and change.
- Strategies: 
1) Top-Down Design
    -- A High level view of the system is broken down into smaller, managable components.
    -- useCase:
        - For solutions which needed to be developed from ground level, this design model is best.

2) Bottom-Up Design
    -- We start we smaller component and piece by piece we combine other components to form a system.
    -- useCase:
        - If something has to be built on-top of an existing system, this design model is best.

3) Incremental Design
    -- Involves designing and development in stages. Once the work completes on the current stage, next Stage work starts. 

4) Iterative Design
    -- Involves designing an development in small parts, more feature added everytime with evey Iteration. 

5) Agile Design
    -- Involves flexible, iterative approach for design and development through collaborative with cross-functional teams.


** Database Sharding ??

- Technique for horizontal [along the ground] Scaling of database.
- Involves split/shrading the data across multiple instances of the database --> improves performance, reduce huge data dump on a single DB instance.
- useCase:
    -- A database with 4 million rows OR 4 databases with each 1 million Rows ? Which one is better ?

- Factors Important For sharding:
1) Data distribution [Data has the shreaded based on some unique keys like id or some hash function]
2) Shard rebalancing [Overtime, when data volume increases, how will we balance each shread/instance of database ]
3) Query Routing [ How will a query knows which shread of database to hit for fetching data ]
4) Data consistency [Data consistency has to be maintained across the shread, could use transaction logs]
5) Failure Handling [How to handle failure, recovery and redistribution of data]
6) Performance. [shreaded database --> Impact on performance and scalability]

- Meaning of Database sharding: 
    -- A database architecture pattern in which large datasets are splitted in smaller chunks (Based on some logic).
    -- This chunks are then stored on differenct instances of the database.
    -- Each node is totally autonomous, they dont share any resources among them.
    -- Distribution has to be done in such a way that, each row appears in exactly one shard.

- Advantages of database sharding ?
    1) Scalability problem solved. [solves the database performance issue with database to manage huge data]
    2) High Availability [Multiple Shard exists, Problem in one shard wont effect others.]
    3) Speed up Query Response Time. [In Monolithic arch, more rows to query i.e more time, In Sharded arch, we know which shard to query i.e faster response]

- Disadvantage of database sharding ?
    1) Add Complexity in the system. [Complicated implementation of sharded system --> might cause data loss or corrupt database]
    2) Rebalancing data. [unbalanced shards i.e one shard holds too much data [database hotspot] compare to other shards, there is a need to rebalance.]
    3) Combining data from multiple shards. [simple joins between the tables from different shards wont work, we need to pull data then join i.e multiple queries needed]

- Sharding Architecture:
1) key based sharding:
    -- Also called hash-based sharding.
    -- Implementation:
       shardKey [CustomerId OR customerEmail OR ZIP] ---> Hash function ----> hashValue [Based on this shard instance is selected.]
    -- usecase:
        - 3 shard instances we have, Our ShardKey or Primary key is applicationId [Unique for every new Data Instance]
        - appId ---> HasFunction --> Val % 3 [3 shard instances present] --> 2 [Data should be put in 2nd shard instance]
    -- Drawback:
        1) Elastic Load balancing [we cannot add or remove shards dynamically, it's a expensive process]
        2) Data must not change over-time, i.e the shardKey must always remain same.
    -- Advantages:
        1) Predictable Data distribution among all shards.
        2) Range based Queries work's faster. [Queries involving fetching data between some given range can fetch data faster]
    -- Disadvantage:
        1) Uneven Data distribution [If shard-key is not well-distributed, Shards might become unbalanced]
        2) Limited scalability with specific keys [with certain keys accessing repeatedly, it is difficult to scale]
        3) Complex Key selection [Choosing the right shardKey in huge dataset can be challenge]

2) horizontal or Range based sharding:
    -- We split the data among shards based on range of the given dataset.
    -- useCase:
       - We have 2 shards of Database and we have customer dataset with their name and product.
       - Shard 1: Stores all customer Info, where customer Name starts with A to P.
         Shard 2: Stores all customer Info, where customer Name starts with Q to Z.
    -- Advantages:
        1) Scalability
        2) Query Performance.
    -- Disadvantage:
        1) Query Performance across shrads.
        2) Shards may become unbalanced because of uneven data distribution.
            - With time, lets say more customer comes with name K, so Shard 1 will be overloaded i.e performace will be impacted.

3) Vertical Sharding
    -- Each Columns of a table is splitted into different tables.
    -- useCase:
        - A client on twitter have profiles, comments and followers.
        - We can Split them into different tables which are in different shards.
    -- Example:
        - A table containing the Name and email with a primary key can be splitted into 2 tables i.e one holds the name and other holds the emails.
    -- Advantages:
        1) Can improve Query Performance.
        2) simplified Query that required to access a specific column.
    -- Disadvantage:
        1) Limited the horizontal Scaling
            - Splitting the table's columns into multiple tables ---> There is a need to scale the servers too.
        2) Possible Hotspot:
            - Possiblities of a columns holding more data i.e table holds more data over time compared to others.
        3) Schema Changes:
            - As a table is splitted based on columns, Any Schema changes needed attention i.e adding/Updating/Removing Columns.

    
4) Directory based Sharding
    -- A Lookup Table is created with the shard key and Shard instance.
    -- Based on the shard key, We can find out Which shard instance stores the data.
    -- useCase:
        - Lets have a table with delivery_Id, location and customerName.
        - We will create a shard lookup table with delivery_id (as shard key) with shard instance id cosntining S1, S2 or S3.
        - Now, Based on the delivery_id, we can exactly say which shard contains the data based on lookup table.
    -- Advantages:
        1) Flexible Data distribution.
            - No Rules has to be followed for distributing the data across shard.
            - the lookup table must contains the shard key with it's respective instance_id.
        2) Efficient Query Routing.
            - Based on lookup, we can route the query to a particular shard.
        3) Dynamic scaling:
            - We can dynamically add or remove the shard, without effecting the system.
            - The shard instance id has to be updated in the lookup table. 
    -- Disadvantage:
        1) Centeralized point to Failure:
            - Eveything depends upon lookup Table, One mistake in the table or becomes unavailable can cause Overall System failure.
        2) Latency
            - First we need to query lookup to Find the shard instance ---> then Query from the shard.
            - This impact the response time of the system.


** horizontal or Vertical Scaling ?

- Scaling Techniques used to handle the capacity and performance of the system.
- In Simple Terms:  
    1) Horizontal scaling or Scale-out (Along the Ground): 
        -- Means Adding more Instances of the server to accomodate the incoming demand.
        -- Adding more server nodes to distribute the incoming workload.
        -- This approach is used by majority as includes increasing i/o conccurrency, reducing load on one server.
        -- Scalability can be acheived with help of distributed file system, Clustering and load-balancing.
        -- Easy to upgrade and run fault tolerence.
        -- useCase:
            - Used for projects with requirement of high availablity or failover.
            - Gamil, Youtube, facebook, amazon all uses horizontal scaling.
        -- Example: 
            Cassandra and Mongo DB
        -- Advantages:
            1) Improved Capacity.
            2) Improved Performance. [WorkLoad is shared among nodes]
            3) Increased fault tolerance. [If one node fails, req can be redirected to other]

        -- Disadvanatages:
            1) Complexity [Managing multiple instances]
            2) Cost [OverTime, Adding and managing multiple instances can add to cost] 

    2) Vertical Scaling or Scale-up (Perpendicular to Ground): 
        -- Means Adding more resources i.e CPU, RAM of a server to Handle processing of more data.
        -- All the trafic resides into one server node with more resource, No Need for any data partions.
        -- Application compatibility is maintained.
        -- example: MySQL and Amazon RDS has vertical Scaling.
        -- usecase:
            - Application has one backend server, to handle more data, Server's Power is increased
            - Server's Resources like CPU and RAM capacity has to be increased
        -- Advantages:
            1) Improvement in Server Performance
            2) Easy Managemenet since only one server node is into play.
        -- Disadvantages:    
            1) Increased Cost: Upgrading server hardware is expensive.
            2) Single point of failure: Only one server, In case of fault/Failure, whole application can be down.
            3) Limited Scalability: Upgrading hardware has it's Limit --> Only able to handle a limited amount of additional Data.

** Load Balancer

- a networking device/Software application that distributes and balance the incoming traffic among the servers.
- ensures high availablity, efficiently server utilization and high performance.
- useCase:
    -- Highly used for cloud application, data center [These places always deals with overwhelmed traffic]
- Practical useCase:
    -- Make sure servers are not overloaded and crash due to high traffic.
- Scenario:
    -- If a Application is running on a single server.
    -- Problems:
        1) If some problem happens with the server. The whole application will be down.
        2) With time, if the user base of the application grows, req traffic will increase. 
            - Server's performance are limit by its hardware can only handle a certain number of req at a time.
            - This leads to server bottle neck ---> Crash the server.
    -- Solution:
        Introduce a load balancer, that depending upon the traffic routes the req to multiple instances of the server.
            1) If any server node fails, Still load balancer can re-route the traffic to other nodes. [high availablity]
            2) It balances the amount req handled by each server nodes, thus maximizing the throughput out of all the servers. [high performance]
            3) More Servers to process data ---> less time between req and res. ---> faster server response.
            4) based on the traffic, more servers node can be dynamically added or removed without any application downtime.    
- Types:
    1) Based on Configuration:
        1) Software Load Balancers:
            - These are software application ---> runs on general purpose servers.
        2) hardware Load Balancers:
            - Physical devices that hanldes Traffic [Also called Layer 4-7 Routers]
            - Can handle all kind of HTTP, HTTPS, TCP, UDP Traffic.
            - Very Expensive to accquire and configure.
            - useCase:
                -- Only used as a first loadbalancer to handle user's request, later software loadbalancers are used to handle the routes.
        3) Virtual Load Balancers:
            - implemented as VM or software instances within a virtual Environment.
            - useCase:
                -- Data centers uses VMs like VMware, Hyper-V.
    
    2) Based on Functions:
        1) Layer 4 (L4):
            - operates at the transport layer.
            - It makes forward decision based on inforamtion in network Layer i.e IP address or PORT
        2) Layer 7 (L7):
            - Operates at application Layer.
            - It makes Forward decision based on content information like URL, HTTP Headers or cookies.
        3) Global Server Load balancer (GSLB): 
            - It basically distributes traffic among geographically distributed servers.
            - It takes server proximity, server health and geo location to decide where to forward the req.

- Load Balancing Algorithms:
    1) Round Robin:
        - Distributes the req in a sequential or rotational manner.
        - simple static implementation approach.
        - It doesn't consider the load on any particular server thus chances of server hotspot.
    2) Weighted Round Robin:
        - static load balancing approach.
        - same as roud-robin with each resources in the list provided with weight score.
        - based on weight score, req are distributed among the servers.
    3) Source IP Hash:
        - Static load balancing approach.
        - used in Netwrok balancing --> based on hashed value of source IP address.
        - req from a particular source always goes to the same server.
    4) Least Connection Method:
        - dynamic load balancing approach.
        - diverts incoming req to servers with least active connections.
        - Aims at reducing load on any particular server ---> prevents server hotspot.
    5) Least Response Time Method:
        - dynamic load balancing approach.
        - diverts incoming req to server with fastest response time.
        - Aims at minimizing the time between the req and res. ---> High performance.

NOTE:
    - A load Balancer enables elastic scalability --> improves performance and throughput of data.
    - It allows to keep many copies of data --> Ensures data availablity in case of any server issue.


